# multi-modal-sentiment-analysis
This project is designed to detect multi-faceted emotions in text and images. In this project, the pre-trained multi-faceted model CLIP is used to analyze and understand text and images. The goal of this model is to select and combine semantic features from both types of data to detect emotions with high accuracy.
